{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j requests"
      ],
      "metadata": {
        "id": "Q0-C9-Xw5Nw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from neo4j import GraphDatabase\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Neo4j credentials.\n",
        "NEO4J_URI = userdata.get('NEO4J_URI')\n",
        "NEO4J_USER = userdata.get('NEO4J_USER')\n",
        "NEO4J_PASSWORD = userdata.get('NEO4J_PASSWORD')\n",
        "\n",
        "# Polymarket Gamma API.\n",
        "GAMMA_API_BASE = 'https://gamma-api.polymarket.com'\n",
        "\n",
        "print('Configuration loaded successfully')"
      ],
      "metadata": {
        "id": "JKaKGfQSNqeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Neo4j driver.\n",
        "neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "print('‚úì Neo4j driver initialized')\n",
        "\n",
        "# Test Gamma API connection.\n",
        "try:\n",
        "    response = requests.get(f'{GAMMA_API_BASE}/markets', timeout=10)\n",
        "    if response.status_code == 200:\n",
        "        print('‚úì Connected to Polymarket Gamma API')\n",
        "    else:\n",
        "        print(f'‚úó Gamma API returned status code: {response.status_code}')\n",
        "except Exception as e:\n",
        "    print(f'‚úó Error connecting to Gamma API: {e}')\n",
        "\n",
        "# Test Blockscout API connection.\n",
        "try:\n",
        "    response = requests.get('https://polygon.blockscout.com/api/v2/stats', timeout=10)\n",
        "    if response.status_code == 200:\n",
        "        print('‚úì Connected to Blockscout API (Polygon)')\n",
        "    else:\n",
        "        print(f'‚úó Blockscout API returned status code: {response.status_code}')\n",
        "except Exception as e:\n",
        "    print(f'‚úó Error connecting to Blockscout API: {e}')\n",
        "\n",
        "print('\\n‚úÖ All clients initialized successfully')"
      ],
      "metadata": {
        "id": "h0ZfJxcVN1Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_latest_events(limit: int = 50) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Fetch the latest active events from Polymarket Gamma API.\"\"\"\n",
        "    try:\n",
        "        url = f'{GAMMA_API_BASE}/events'\n",
        "        params = {\n",
        "            'limit': limit,\n",
        "            'offset': 0,\n",
        "            'closed': 'true',\n",
        "            'order': 'id',\n",
        "            'ascending': 'false'\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        return response.json()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error fetching events: {e}')\n",
        "        return []\n",
        "\n",
        "# Fetch events (including closed ones since token transfers are historical).\n",
        "latest_events = fetch_latest_events(10)\n",
        "total_markets = sum(len(event.get('markets', [])) for event in latest_events)\n",
        "\n",
        "print(f'Fetched {len(latest_events)} events and {total_markets} markets.')"
      ],
      "metadata": {
        "id": "HSloVEFxOIyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extract_category_from_tags(event: Dict[str, Any]) -> str:\n",
        "    \"\"\"Extract category from event tags.\"\"\"\n",
        "    if event.get('category'):\n",
        "        return event['category']\n",
        "\n",
        "    tags = event.get('tags', [])\n",
        "    priority_categories = ['Sports', 'Politics', 'Finance', 'Crypto', 'Science', 'Entertainment']\n",
        "\n",
        "    for tag in tags:\n",
        "        label = tag.get('label', '')\n",
        "        if label in priority_categories:\n",
        "            return label\n",
        "\n",
        "    for tag in tags:\n",
        "        label = tag.get('label', '')\n",
        "        if label and label not in ['All', 'Hide From New', 'Daily', 'Recurring']:\n",
        "            return label\n",
        "\n",
        "    return 'Unknown'\n",
        "\n",
        "def extract_outcomes_from_market(market: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Extract outcomes with token IDs and prices from market.\"\"\"\n",
        "    outcomes_str = market.get('outcomes', '[]')\n",
        "    outcome_names = json.loads(outcomes_str) if isinstance(outcomes_str, str) else (outcomes_str or [])\n",
        "\n",
        "    prices_str = market.get('outcomePrices', '[]')\n",
        "    prices = json.loads(prices_str) if isinstance(prices_str, str) else (prices_str or [])\n",
        "\n",
        "    token_ids_str = market.get('clobTokenIds', '[]')\n",
        "    token_ids = json.loads(token_ids_str) if isinstance(token_ids_str, str) else (token_ids_str or [])\n",
        "\n",
        "    outcomes = []\n",
        "    for i, outcome_name in enumerate(outcome_names):\n",
        "        outcomes.append({\n",
        "            'token_id': token_ids[i] if i < len(token_ids) else f\"unknown_{market['id']}_{i}\",\n",
        "            'name': outcome_name,  # Changed from 'outcome_name' to 'name'\n",
        "            'price': prices[i] if i < len(prices) else '0.5',  # Changed from 'current_price' to 'price'\n",
        "            'condition_id': market.get('conditionId'),  # Added for linking trades to markets\n",
        "        })\n",
        "\n",
        "    return outcomes\n",
        "\n",
        "# Process events.\n",
        "print('Processing events...')\n",
        "for event in latest_events:\n",
        "    event['category'] = extract_category_from_tags(event)\n",
        "\n",
        "categories = set(event['category'] for event in latest_events)\n",
        "print(f'  Categories: {\", \".join(categories)}')\n",
        "\n",
        "# Extract outcomes.\n",
        "print('Extracting outcomes and condition IDs...')\n",
        "all_outcomes = []\n",
        "all_condition_ids = set()\n",
        "\n",
        "for event in latest_events:\n",
        "    for market in event.get('markets', []):\n",
        "        outcomes = extract_outcomes_from_market(market)\n",
        "        all_outcomes.extend(outcomes)\n",
        "\n",
        "        # Collect condition IDs for trade filtering.\n",
        "        condition_id = market.get('conditionId')\n",
        "        if condition_id:\n",
        "            all_condition_ids.add(condition_id)\n",
        "\n",
        "print(f'  Outcomes: {len(all_outcomes)} (from {total_markets} markets)')\n",
        "print(f'  Unique Condition IDs: {len(all_condition_ids)}')\n",
        "\n",
        "# Collect all token IDs for later (not used for blockchain matching anymore).\n",
        "outcome_token_ids = set(outcome['token_id'] for outcome in all_outcomes if not outcome['token_id'].startswith('unknown_'))\n",
        "print(f'  Valid Token IDs: {len(outcome_token_ids)}')\n",
        "\n",
        "# USDC address.\n",
        "usdc_address = '0x2791Bca1f2de4661ED88A30C99A7a9449Aa84174'\n",
        "\n",
        "print('\\n‚úÖ Polymarket data processed')"
      ],
      "metadata": {
        "id": "5hufwCeNONx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_trades_from_data_api(condition_ids: List[str] = None, max_trades: int = None, batch_desc: str = '') -> List[Dict[str, Any]]:\n",
        "    \"\"\"Fetch ALL trades from Polymarket Data API with pagination.\"\"\"\n",
        "    import time as time_module\n",
        "    from tqdm.notebook import tqdm\n",
        "\n",
        "    url = 'https://data-api.polymarket.com/trades'\n",
        "    all_trades = []\n",
        "    offset = 0\n",
        "    page_size = 500  # Polymarket API hard limit is 500 per request\n",
        "\n",
        "    # Create a progress bar without a known total (will just count up)\n",
        "    pbar = tqdm(total=None, desc=f'{batch_desc}', unit=' trades', position=1, leave=False, bar_format='{desc}: {n_fmt} trades fetched')\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            params = {\n",
        "                'limit': page_size,\n",
        "                'offset': offset,\n",
        "                'takerOnly': 'true'\n",
        "            }\n",
        "\n",
        "            # Add market filter if condition IDs provided.\n",
        "            if condition_ids:\n",
        "                params['market'] = ','.join(condition_ids)\n",
        "\n",
        "            response = requests.get(url, params=params, timeout=30)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                pbar.write(f'    ‚ö† Error: HTTP {response.status_code}')\n",
        "                break\n",
        "\n",
        "            trades = response.json()\n",
        "\n",
        "            if len(trades) == 0:\n",
        "                break\n",
        "\n",
        "            # Transform to our format and extract ALL data from Polymarket API.\n",
        "            for trade in trades:\n",
        "                all_trades.append({\n",
        "                    'hash': trade.get('transactionHash', ''),\n",
        "                    'from': trade.get('proxyWallet', ''),\n",
        "                    'to': '',\n",
        "                    'side': trade.get('side', ''),\n",
        "                    'condition_id': trade.get('conditionId', ''),\n",
        "                    'outcome': trade.get('outcome', ''),\n",
        "                    'outcome_index': trade.get('outcomeIndex', 0),\n",
        "                    'size': float(trade.get('size', 0)),\n",
        "                    'price': float(trade.get('price', 0)),\n",
        "                    'timestamp': trade.get('timestamp', 0),\n",
        "                    'asset': trade.get('asset', ''),\n",
        "                    'market_slug': trade.get('slug', ''),\n",
        "                    'market_title': trade.get('title', ''),\n",
        "                    'market_icon': trade.get('icon', ''),\n",
        "                    'event_slug': trade.get('eventSlug', ''),\n",
        "                    'user_name': trade.get('name', ''),\n",
        "                    'user_pseudonym': trade.get('pseudonym', ''),\n",
        "                    'user_bio': trade.get('bio', ''),\n",
        "                    'user_profile_image': trade.get('profileImage', ''),\n",
        "                    'user_profile_image_optimized': trade.get('profileImageOptimized', ''),\n",
        "                })\n",
        "\n",
        "            # Update progress bar with new trade count\n",
        "            pbar.n = len(all_trades)\n",
        "            pbar.refresh()\n",
        "\n",
        "            # Check if we've reached the max trades limit.\n",
        "            if max_trades and len(all_trades) >= max_trades:\n",
        "                all_trades = all_trades[:max_trades]\n",
        "                pbar.write(f'    ‚Ñπ Reached limit of {max_trades:,} trades for this batch')\n",
        "                break\n",
        "\n",
        "            # Check if we got fewer trades than the page size (end of data).\n",
        "            if len(trades) < page_size:\n",
        "                break\n",
        "\n",
        "            # Move to next page.\n",
        "            offset += len(trades)\n",
        "\n",
        "            # Rate limiting to avoid hitting API limits.\n",
        "            time_module.sleep(0.3)\n",
        "\n",
        "        pbar.close()\n",
        "        return all_trades\n",
        "\n",
        "    except Exception as e:\n",
        "        pbar.close()\n",
        "        print(f'    ‚ö† Error: {e}')\n",
        "        return all_trades\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print('Fetching ALL trades from Polymarket Data API...')\n",
        "print(f'Strategy: Fetch trades per market individually (max 10,000 trades per market)\\n')\n",
        "\n",
        "# Fetch trades per market individually to ensure fair distribution\n",
        "condition_id_list = list(all_condition_ids)\n",
        "all_token_transfers = []\n",
        "\n",
        "print(f'Total markets: {len(condition_id_list)}')\n",
        "print(f'Limit: 10,000 trades per market (to prevent single active markets from dominating)\\n')\n",
        "\n",
        "# Create progress bar for markets\n",
        "for i, condition_id in enumerate(tqdm(condition_id_list, desc='Fetching Markets', unit='market', position=0)):\n",
        "    market_desc = f'Market {i+1}/{len(condition_id_list)}'\n",
        "\n",
        "    # Fetch trades for single market with 10,000 trade limit\n",
        "    trades = fetch_trades_from_data_api(condition_ids=[condition_id], max_trades=10000, batch_desc=market_desc)\n",
        "    all_token_transfers.extend(trades)\n",
        "\n",
        "print(f'\\n‚úÖ Completed!')\n",
        "\n",
        "print(f'\\nüìä Total: Fetched {len(all_token_transfers)} trades\\n')\n",
        "\n",
        "if len(all_token_transfers) > 0:\n",
        "    # Get unique condition IDs from trades.\n",
        "    fetched_condition_ids = set(t['condition_id'] for t in all_token_transfers if t['condition_id'])\n",
        "\n",
        "    # Get unique users.\n",
        "    users = set(t['from'] for t in all_token_transfers if t['from'])\n",
        "\n",
        "    # Calculate total volume.\n",
        "    total_volume = sum(t['size'] for t in all_token_transfers)\n",
        "\n",
        "    print(f'üìä Trade Statistics:')\n",
        "    print(f'‚îÄ' * 70)\n",
        "    print(f'  Total Trades:         {len(all_token_transfers):,}')\n",
        "    print(f'  Markets Requested:    {len(all_condition_ids)}')\n",
        "    print(f'  Markets with Trades:  {len(fetched_condition_ids)}')\n",
        "    print(f'  Unique Users:         {len(users):,}')\n",
        "    print(f'  Total Volume:         ${total_volume:,.2f} USDC')\n",
        "    if len(all_token_transfers) > 0:\n",
        "        print(f'  Average Trade Size:   ${total_volume / len(all_token_transfers):,.2f} USDC')\n",
        "    print(f'‚îÄ' * 70)\n",
        "\n",
        "    # Check for markets with no trades\n",
        "    missing_condition_ids = all_condition_ids - fetched_condition_ids\n",
        "    if len(missing_condition_ids) > 0:\n",
        "        print(f'\\n‚ö†Ô∏è  Warning: {len(missing_condition_ids)} markets returned NO trades:')\n",
        "        print(f'   This could mean:')\n",
        "        print(f'   ‚Ä¢ Markets are too old (API might not have historical data)')\n",
        "        print(f'   ‚Ä¢ Markets had no trading activity')\n",
        "        print(f'   ‚Ä¢ API filtering issue with those condition IDs')\n",
        "        print(f'\\n   Missing condition IDs (first 5):')\n",
        "        for cid in list(missing_condition_ids)[:5]:\n",
        "            print(f'   ‚Ä¢ {cid}')\n",
        "        if len(missing_condition_ids) > 5:\n",
        "            print(f'   ... and {len(missing_condition_ids) - 5} more')\n",
        "\n",
        "    print(f'\\n‚úÖ Successfully collected {len(all_token_transfers):,} trades for our markets!')\n",
        "else:\n",
        "    print('\\n‚ö†Ô∏è  WARNING: No trades fetched!')\n",
        "    print('    Possible reasons:')\n",
        "    print('    - Markets are too new/old')\n",
        "    print('    - API filter syntax issue')\n",
        "    print('    - Markets have no trading activity')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xFiqD_qoORl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print('=' * 70)\n",
        "print('Importing Data to Neo4j')\n",
        "print('=' * 70)\n",
        "print()\n",
        "\n",
        "# Prepare user data from trades with Polymarket profile data.\n",
        "print('[0/10] Preparing user data...')\n",
        "user_profiles = {}\n",
        "null_address = '0x0000000000000000000000000000000000000000'\n",
        "\n",
        "for trade in all_token_transfers:\n",
        "    trader_addr = trade.get('from')\n",
        "    if not trader_addr or trader_addr == null_address:\n",
        "        continue\n",
        "\n",
        "    if trader_addr not in user_profiles:\n",
        "        user_profiles[trader_addr] = {\n",
        "            'address': trader_addr,\n",
        "            'role': 'trader',\n",
        "            'name': trade.get('user_name', ''),\n",
        "            'pseudonym': trade.get('user_pseudonym', ''),\n",
        "            'bio': trade.get('user_bio', ''),\n",
        "            'profile_image': trade.get('user_profile_image', ''),\n",
        "            'profile_image_optimized': trade.get('user_profile_image_optimized', ''),\n",
        "        }\n",
        "\n",
        "print(f'  ‚úì Prepared {len(user_profiles)} users\\n')\n",
        "\n",
        "def create_schema(driver):\n",
        "    \"\"\"Create constraints and indexes.\"\"\"\n",
        "    print('[1/9] Creating schema...')\n",
        "\n",
        "    statements = [\n",
        "        # Constraints.\n",
        "        'CREATE CONSTRAINT user_address IF NOT EXISTS FOR (u:User) REQUIRE u.address IS UNIQUE',\n",
        "        'CREATE CONSTRAINT event_slug IF NOT EXISTS FOR (e:Event) REQUIRE e.slug IS UNIQUE',\n",
        "        'CREATE CONSTRAINT market_condition_id IF NOT EXISTS FOR (m:Market) REQUIRE m.condition_id IS UNIQUE',\n",
        "        'CREATE CONSTRAINT outcome_id IF NOT EXISTS FOR (o:Outcome) REQUIRE (o.condition_id, o.outcome_index) IS UNIQUE',\n",
        "        'CREATE CONSTRAINT trade_hash IF NOT EXISTS FOR (t:Trade) REQUIRE t.transaction_hash IS UNIQUE',\n",
        "\n",
        "        # Indexes.\n",
        "        'CREATE INDEX event_category IF NOT EXISTS FOR (e:Event) ON (e.category)',\n",
        "        'CREATE INDEX event_closed IF NOT EXISTS FOR (e:Event) ON (e.closed)',\n",
        "        'CREATE INDEX market_slug IF NOT EXISTS FOR (m:Market) ON (m.slug)',\n",
        "        'CREATE INDEX trade_timestamp IF NOT EXISTS FOR (t:Trade) ON (t.timestamp)',\n",
        "        'CREATE INDEX trade_side IF NOT EXISTS FOR (t:Trade) ON (t.side)',\n",
        "        'CREATE INDEX user_role IF NOT EXISTS FOR (u:User) ON (u.role)',\n",
        "    ]\n",
        "\n",
        "    with driver.session() as session:\n",
        "        for stmt in statements:\n",
        "            try:\n",
        "                session.run(stmt)\n",
        "            except Exception:\n",
        "                pass  # Constraint/index may already exist\n",
        "\n",
        "    print('  ‚úì Schema created\\n')\n",
        "\n",
        "def clear_database(driver):\n",
        "    \"\"\"Clear all data.\"\"\"\n",
        "    print('[2/9] Clearing database...')\n",
        "    with driver.session() as session:\n",
        "        session.run('MATCH (n) DETACH DELETE n')\n",
        "    print('  ‚úì Database cleared\\n')\n",
        "\n",
        "def import_events(driver, events):\n",
        "    \"\"\"Import Event nodes in batch.\"\"\"\n",
        "    print('[3/9] Importing events...')\n",
        "\n",
        "    # Prepare data.\n",
        "    event_data = []\n",
        "    for event in events:\n",
        "        tags = event.get('tags', [])\n",
        "        tag_labels = [tag.get('label', '') for tag in tags if tag.get('label')]\n",
        "\n",
        "        event_data.append({\n",
        "            'slug': event.get('slug'),\n",
        "            'title': event.get('title', ''),\n",
        "            'description': event.get('description', ''),\n",
        "            'category': event.get('category', 'Unknown'),\n",
        "            'start_date': event.get('startDate', '2020-01-01T00:00:00Z'),\n",
        "            'end_date': event.get('endDate', '2030-01-01T00:00:00Z'),\n",
        "            'closed': event.get('closed', False),\n",
        "            'volume': event.get('volume', 0),\n",
        "            'liquidity': event.get('liquidity', 0) if event.get('liquidity') else 0,\n",
        "            'open_interest': event.get('openInterest', 0),\n",
        "            'icon': event.get('icon', ''),\n",
        "            'image': event.get('image', ''),\n",
        "            'comment_count': event.get('commentCount', 0),\n",
        "            'tags': tag_labels,\n",
        "            'restricted': event.get('restricted', False),\n",
        "            'featured': event.get('featured', False),\n",
        "        })\n",
        "\n",
        "    # Batch import using UNWIND.\n",
        "    with driver.session() as session:\n",
        "        session.run('''\n",
        "            UNWIND $events as event\n",
        "            MERGE (e:Event {slug: event.slug})\n",
        "            SET e.title = event.title,\n",
        "                e.description = event.description,\n",
        "                e.category = event.category,\n",
        "                e.start_date = datetime(event.start_date),\n",
        "                e.end_date = datetime(event.end_date),\n",
        "                e.closed = event.closed,\n",
        "                e.volume = toFloat(event.volume),\n",
        "                e.liquidity = toFloat(event.liquidity),\n",
        "                e.open_interest = toFloat(event.open_interest),\n",
        "                e.icon = event.icon,\n",
        "                e.image = event.image,\n",
        "                e.comment_count = toInteger(event.comment_count),\n",
        "                e.tags = event.tags,\n",
        "                e.restricted = event.restricted,\n",
        "                e.featured = event.featured\n",
        "        ''', {'events': event_data})\n",
        "\n",
        "    print(f'  ‚úì Imported {len(events)} events\\n')\n",
        "\n",
        "def import_markets(driver, events):\n",
        "    \"\"\"Import Market nodes in batches.\"\"\"\n",
        "    print('[4/9] Importing markets...')\n",
        "\n",
        "    # Prepare market data.\n",
        "    market_data = []\n",
        "\n",
        "    for event in events:\n",
        "        event_slug = event.get('slug')\n",
        "\n",
        "        for market in event.get('markets', []):\n",
        "            condition_id = market.get('conditionId')\n",
        "            if not condition_id:\n",
        "                continue\n",
        "\n",
        "            # Determine resolution status.\n",
        "            closed = market.get('closed', False)\n",
        "            uma_resolution_status = market.get('umaResolutionStatus', '')\n",
        "            resolved = uma_resolution_status == 'resolved'\n",
        "            winning_outcome = None\n",
        "\n",
        "            if resolved:\n",
        "                outcome_prices_str = market.get('outcomePrices', '[]')\n",
        "                try:\n",
        "                    outcome_prices = json.loads(outcome_prices_str) if isinstance(outcome_prices_str, str) else outcome_prices_str\n",
        "                    outcomes_str = market.get('outcomes', '[]')\n",
        "                    outcome_names = json.loads(outcomes_str) if isinstance(outcomes_str, str) else outcomes_str\n",
        "\n",
        "                    for i, price in enumerate(outcome_prices):\n",
        "                        if float(price) >= 0.99:\n",
        "                            winning_outcome = outcome_names[i] if i < len(outcome_names) else None\n",
        "                            break\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            # Convert closedTime format.\n",
        "            closed_time = market.get('closedTime', '')\n",
        "            if closed_time:\n",
        "                try:\n",
        "                    closed_time = closed_time.replace(' ', 'T').replace('+00', 'Z')\n",
        "                except Exception:\n",
        "                    closed_time = '2020-01-01T00:00:00Z'\n",
        "            else:\n",
        "                closed_time = '2020-01-01T00:00:00Z'\n",
        "\n",
        "            market_data.append({\n",
        "                'condition_id': condition_id,\n",
        "                'question': market.get('question', ''),\n",
        "                'slug': market.get('slug', ''),\n",
        "                'description': market.get('description', ''),\n",
        "                'question_id': market.get('questionID', ''),\n",
        "                'start_date': market.get('startDate', '2020-01-01T00:00:00Z'),\n",
        "                'end_date': market.get('endDate', '2030-01-01T00:00:00Z'),\n",
        "                'closed': closed,\n",
        "                'closed_time': closed_time,\n",
        "                'resolved': resolved,\n",
        "                'winning_outcome': winning_outcome,\n",
        "                'resolved_by': market.get('resolvedBy', ''),\n",
        "                'uma_resolution_status': uma_resolution_status,\n",
        "                'volume': market.get('volumeNum', 0),\n",
        "                'volume_clob': market.get('volumeClob', 0),\n",
        "                'liquidity': market.get('liquidityNum', 0) if market.get('liquidityNum') else 0,\n",
        "                'last_trade_price': market.get('lastTradePrice', 0),\n",
        "                'best_ask': market.get('bestAsk', 0),\n",
        "                'best_bid': market.get('bestBid', 0),\n",
        "                'spread': market.get('spread', 0),\n",
        "                'neg_risk': market.get('negRisk', False),\n",
        "                'neg_risk_market_id': market.get('negRiskMarketID'),\n",
        "                'group_item_title': market.get('groupItemTitle'),\n",
        "                'group_item_threshold': market.get('groupItemThreshold'),\n",
        "                'restricted': market.get('restricted', False),\n",
        "                'active': market.get('active', True),\n",
        "                'event_slug': event_slug,\n",
        "            })\n",
        "\n",
        "    # Batch import markets.\n",
        "    with driver.session() as session:\n",
        "        session.run('''\n",
        "            UNWIND $markets as market\n",
        "            MERGE (m:Market {condition_id: market.condition_id})\n",
        "            SET m.question = market.question,\n",
        "                m.slug = market.slug,\n",
        "                m.description = market.description,\n",
        "                m.question_id = market.question_id,\n",
        "                m.start_date = datetime(market.start_date),\n",
        "                m.end_date = datetime(market.end_date),\n",
        "                m.closed = market.closed,\n",
        "                m.closed_time = datetime(market.closed_time),\n",
        "                m.resolved = market.resolved,\n",
        "                m.winning_outcome = market.winning_outcome,\n",
        "                m.resolved_by = market.resolved_by,\n",
        "                m.uma_resolution_status = market.uma_resolution_status,\n",
        "                m.volume = toFloat(market.volume),\n",
        "                m.volume_clob = toFloat(market.volume_clob),\n",
        "                m.liquidity = toFloat(market.liquidity),\n",
        "                m.last_trade_price = toFloat(market.last_trade_price),\n",
        "                m.best_ask = toFloat(market.best_ask),\n",
        "                m.best_bid = toFloat(market.best_bid),\n",
        "                m.spread = toFloat(market.spread),\n",
        "                m.neg_risk = market.neg_risk,\n",
        "                m.neg_risk_market_id = market.neg_risk_market_id,\n",
        "                m.group_item_title = market.group_item_title,\n",
        "                m.group_item_threshold = market.group_item_threshold,\n",
        "                m.restricted = market.restricted,\n",
        "                m.active = market.active\n",
        "        ''', {'markets': market_data})\n",
        "\n",
        "        # Create Market -> Event relationships.\n",
        "        session.run('''\n",
        "            UNWIND $markets as market\n",
        "            MATCH (m:Market {condition_id: market.condition_id})\n",
        "            MATCH (e:Event {slug: market.event_slug})\n",
        "            MERGE (m)-[:PART_OF_EVENT]->(e)\n",
        "        ''', {'markets': market_data})\n",
        "\n",
        "    print(f'  ‚úì Imported {len(market_data)} markets\\n')\n",
        "\n",
        "def import_outcomes(driver, events):\n",
        "    \"\"\"Import Outcome nodes in batches.\"\"\"\n",
        "    print('[5/9] Importing outcomes...')\n",
        "\n",
        "    # Prepare outcome data.\n",
        "    outcome_data = []\n",
        "\n",
        "    for event in events:\n",
        "        for market in event.get('markets', []):\n",
        "            condition_id = market.get('conditionId')\n",
        "            if not condition_id:\n",
        "                continue\n",
        "\n",
        "            # Parse outcomes.\n",
        "            outcomes_str = market.get('outcomes', '[]')\n",
        "            outcome_names = json.loads(outcomes_str) if isinstance(outcomes_str, str) else (outcomes_str or [])\n",
        "\n",
        "            prices_str = market.get('outcomePrices', '[]')\n",
        "            prices = json.loads(prices_str) if isinstance(prices_str, str) else (prices_str or [])\n",
        "\n",
        "            token_ids_str = market.get('clobTokenIds', '[]')\n",
        "            token_ids = json.loads(token_ids_str) if isinstance(token_ids_str, str) else (token_ids_str or [])\n",
        "\n",
        "            for i, outcome_name in enumerate(outcome_names):\n",
        "                outcome_data.append({\n",
        "                    'condition_id': condition_id,\n",
        "                    'outcome_index': i,\n",
        "                    'outcome_name': outcome_name,\n",
        "                    'current_price': prices[i] if i < len(prices) else 0.5,\n",
        "                    'token_id': token_ids[i] if i < len(token_ids) else '',\n",
        "                })\n",
        "\n",
        "    # Batch import outcomes.\n",
        "    with driver.session() as session:\n",
        "        session.run('''\n",
        "            UNWIND $outcomes as outcome\n",
        "            MERGE (o:Outcome {condition_id: outcome.condition_id, outcome_index: outcome.outcome_index})\n",
        "            SET o.outcome_name = outcome.outcome_name,\n",
        "                o.current_price = toFloat(outcome.current_price),\n",
        "                o.token_id = outcome.token_id\n",
        "        ''', {'outcomes': outcome_data})\n",
        "\n",
        "        # Create Market -> Outcome relationships.\n",
        "        session.run('''\n",
        "            UNWIND $outcomes as outcome\n",
        "            MATCH (o:Outcome {condition_id: outcome.condition_id, outcome_index: outcome.outcome_index})\n",
        "            MATCH (m:Market {condition_id: outcome.condition_id})\n",
        "            MERGE (m)-[:HAS_OUTCOME]->(o)\n",
        "        ''', {'outcomes': outcome_data})\n",
        "\n",
        "    print(f'  ‚úì Imported {len(outcome_data)} outcomes\\n')\n",
        "\n",
        "def import_users(driver, users):\n",
        "    \"\"\"Import User nodes with Polymarket profile data.\"\"\"\n",
        "    print('[6/9] Importing users...')\n",
        "\n",
        "    # Prepare user data.\n",
        "    user_data = []\n",
        "    for user in users.values():\n",
        "        user_data.append({\n",
        "            'address': user['address'],\n",
        "            'role': 'trader',\n",
        "            'name': user.get('name', ''),\n",
        "            'pseudonym': user.get('pseudonym', ''),\n",
        "            'bio': user.get('bio', ''),\n",
        "            'profile_image': user.get('profile_image', ''),\n",
        "            'profile_image_optimized': user.get('profile_image_optimized', ''),\n",
        "        })\n",
        "\n",
        "    # Batch import users.\n",
        "    with driver.session() as session:\n",
        "        session.run('''\n",
        "            UNWIND $users as user\n",
        "            MERGE (u:User {address: user.address})\n",
        "            SET u.role = user.role,\n",
        "                u.name = user.name,\n",
        "                u.pseudonym = user.pseudonym,\n",
        "                u.bio = user.bio,\n",
        "                u.profile_image = user.profile_image,\n",
        "                u.profile_image_optimized = user.profile_image_optimized\n",
        "        ''', {'users': user_data})\n",
        "\n",
        "    print(f'  ‚úì Imported {len(users)} users\\n')\n",
        "\n",
        "def import_trades(driver, trades):\n",
        "    \"\"\"Import Trade nodes in batches for speed.\"\"\"\n",
        "    print('[7/9] Importing trades...')\n",
        "\n",
        "    batch_size = 500  # Process 500 trades at a time\n",
        "    total_batches = (len(trades) + batch_size - 1) // batch_size\n",
        "\n",
        "    imported_count = 0\n",
        "    skipped_count = 0\n",
        "\n",
        "    with driver.session() as session:\n",
        "        for batch_idx in tqdm(range(0, len(trades), batch_size), desc='  Trade Batches', unit='batch', total=total_batches):\n",
        "            batch = trades[batch_idx:batch_idx + batch_size]\n",
        "\n",
        "            # Prepare batch data.\n",
        "            trade_data = []\n",
        "            for trade in batch:\n",
        "                tx_hash = trade.get('hash')\n",
        "                condition_id = trade.get('condition_id')\n",
        "                trader_address = trade.get('from')\n",
        "\n",
        "                if not tx_hash or not condition_id or not trader_address:\n",
        "                    skipped_count += 1\n",
        "                    continue\n",
        "\n",
        "                # Parse timestamp.\n",
        "                timestamp_value = trade.get('timestamp')\n",
        "                if timestamp_value:\n",
        "                    try:\n",
        "                        timestamp_iso = datetime.fromtimestamp(int(timestamp_value)).isoformat()\n",
        "                    except Exception:\n",
        "                        timestamp_iso = datetime.now().isoformat()\n",
        "                else:\n",
        "                    timestamp_iso = datetime.now().isoformat()\n",
        "\n",
        "                trade_data.append({\n",
        "                    'transaction_hash': tx_hash,\n",
        "                    'timestamp': timestamp_iso,\n",
        "                    'side': trade.get('side', 'BUY'),\n",
        "                    'size_usdc': trade.get('size', 0),\n",
        "                    'price': trade.get('price', 0),\n",
        "                    'outcome_name': trade.get('outcome', ''),\n",
        "                    'outcome_index': trade.get('outcome_index', 0),\n",
        "                    'market_title': trade.get('market_title', ''),\n",
        "                    'market_slug': trade.get('market_slug', ''),\n",
        "                    'event_slug': trade.get('event_slug', ''),\n",
        "                    'trader_address': trader_address,\n",
        "                    'condition_id': condition_id,\n",
        "                })\n",
        "\n",
        "            if not trade_data:\n",
        "                continue\n",
        "\n",
        "            # Batch import trades.\n",
        "            session.run('''\n",
        "                UNWIND $trades as trade\n",
        "                MERGE (t:Trade {transaction_hash: trade.transaction_hash})\n",
        "                SET t.timestamp = datetime(trade.timestamp),\n",
        "                    t.side = trade.side,\n",
        "                    t.size_usdc = toFloat(trade.size_usdc),\n",
        "                    t.price = toFloat(trade.price),\n",
        "                    t.outcome_name = trade.outcome_name,\n",
        "                    t.outcome_index = toInteger(trade.outcome_index),\n",
        "                    t.market_title = trade.market_title,\n",
        "                    t.market_slug = trade.market_slug,\n",
        "                    t.event_slug = trade.event_slug\n",
        "            ''', {'trades': trade_data})\n",
        "\n",
        "            # Batch create User->Trade relationships.\n",
        "            session.run('''\n",
        "                UNWIND $trades as trade\n",
        "                MATCH (t:Trade {transaction_hash: trade.transaction_hash})\n",
        "                MATCH (u:User {address: trade.trader_address})\n",
        "                MERGE (u)-[:PLACED_TRADE]->(t)\n",
        "            ''', {'trades': trade_data})\n",
        "\n",
        "            # Batch create Trade->Market relationships.\n",
        "            session.run('''\n",
        "                UNWIND $trades as trade\n",
        "                MATCH (t:Trade {transaction_hash: trade.transaction_hash})\n",
        "                MATCH (m:Market {condition_id: trade.condition_id})\n",
        "                MERGE (t)-[:ON_MARKET]->(m)\n",
        "            ''', {'trades': trade_data})\n",
        "\n",
        "            # Batch create Trade->Outcome relationships.\n",
        "            session.run('''\n",
        "                UNWIND $trades as trade\n",
        "                MATCH (t:Trade {transaction_hash: trade.transaction_hash})\n",
        "                MATCH (o:Outcome {condition_id: trade.condition_id, outcome_index: trade.outcome_index})\n",
        "                MERGE (t)-[:FOR_OUTCOME]->(o)\n",
        "            ''', {'trades': trade_data})\n",
        "\n",
        "            imported_count += len(trade_data)\n",
        "\n",
        "    print(f'  ‚úì Imported {imported_count} trades ({skipped_count} skipped)\\n')\n",
        "\n",
        "def create_group_market_relationships(driver, events):\n",
        "    \"\"\"Link markets in the same group.\"\"\"\n",
        "    print('[8/9] Creating group market relationships...')\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    with driver.session() as session:\n",
        "        for event in events:\n",
        "            for market in event.get('markets', []):\n",
        "                neg_risk_market_id = market.get('negRiskMarketID')\n",
        "                condition_id = market.get('conditionId')\n",
        "\n",
        "                if neg_risk_market_id and condition_id:\n",
        "                    session.run('''\n",
        "                        MATCH (m1:Market {condition_id: $condition_id})\n",
        "                        MATCH (m2:Market)\n",
        "                        WHERE m2.neg_risk_market_id = $neg_risk_market_id\n",
        "                          AND m1.condition_id <> m2.condition_id\n",
        "                        MERGE (m1)-[:SAME_GROUP {group_id: $neg_risk_market_id}]->(m2)\n",
        "                    ''', {\n",
        "                        'condition_id': condition_id,\n",
        "                        'neg_risk_market_id': neg_risk_market_id,\n",
        "                    })\n",
        "                    count += 1\n",
        "\n",
        "    print(f'  ‚úì Created relationships for {count} group markets\\n')\n",
        "\n",
        "def create_holdings(driver):\n",
        "    \"\"\"Calculate user holdings from BUY trades.\"\"\"\n",
        "    print('[9/9] Creating holdings...')\n",
        "\n",
        "    with driver.session() as session:\n",
        "        result = session.run('''\n",
        "            MATCH (u:User)-[:PLACED_TRADE]->(t:Trade)-[:FOR_OUTCOME]->(o:Outcome)\n",
        "            WHERE t.side = 'BUY'\n",
        "            WITH u, o, sum(t.size_usdc) as total_invested, max(t.timestamp) as last_trade\n",
        "            MERGE (u)-[h:HOLDS]->(o)\n",
        "            SET h.invested_usdc = total_invested,\n",
        "                h.last_updated = last_trade\n",
        "            RETURN count(*) as holdings_created\n",
        "        ''')\n",
        "\n",
        "        count = result.single()['holdings_created']\n",
        "\n",
        "    print(f'  ‚úì Created {count} holdings\\n')\n",
        "\n",
        "# Main execution.\n",
        "print('Starting Neo4j import...\\n')\n",
        "\n",
        "create_schema(neo4j_driver)\n",
        "clear_database(neo4j_driver)\n",
        "import_events(neo4j_driver, latest_events)\n",
        "import_markets(neo4j_driver, latest_events)\n",
        "import_outcomes(neo4j_driver, latest_events)\n",
        "import_users(neo4j_driver, user_profiles)\n",
        "import_trades(neo4j_driver, all_token_transfers)\n",
        "create_group_market_relationships(neo4j_driver, latest_events)\n",
        "create_holdings(neo4j_driver)\n",
        "\n",
        "print('=' * 70)\n",
        "print('‚úÖ Data import complete!')\n",
        "print('=' * 70)\n",
        "print()\n",
        "print('Summary:')\n",
        "print(f'  ‚Ä¢ Events: {len(latest_events)}')\n",
        "print(f'  ‚Ä¢ Markets: {total_markets}')\n",
        "print(f'  ‚Ä¢ Outcomes: {len(all_outcomes)}')\n",
        "print(f'  ‚Ä¢ Trades: {len(all_token_transfers)}')\n",
        "print(f'  ‚Ä¢ Users: {len(user_profiles)}')\n",
        "print('=' * 70)\n"
      ],
      "metadata": {
        "id": "qUpElzt7rFiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print('=' * 70)\n",
        "print('Verifying Neo4j Database')\n",
        "print('=' * 70)\n",
        "print()\n",
        "\n",
        "def verify_database(driver):\n",
        "    \"\"\"Run comprehensive verification queries.\"\"\"\n",
        "\n",
        "    with driver.session() as session:\n",
        "        # ====================================================================\n",
        "        # 1. NODE COUNTS\n",
        "        # ====================================================================\n",
        "        print('[1/7] Counting Nodes...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        node_types = ['Event', 'Market', 'Outcome', 'User', 'Contract', 'Trade']\n",
        "        node_counts = {}\n",
        "\n",
        "        for node_type in tqdm(node_types, desc='Node Types'):\n",
        "            result = session.run(f'MATCH (n:{node_type}) RETURN count(n) as count')\n",
        "            node_counts[node_type] = result.single()['count']\n",
        "            print(f'  ‚Ä¢ {node_type}: {node_counts[node_type]:,}')\n",
        "\n",
        "        # Specific counts.\n",
        "        result = session.run('MATCH (u:User) WHERE u.role = \"trader\" RETURN count(u) as count')\n",
        "        trader_count = result.single()['count']\n",
        "        print(f'  ‚Ä¢ Traders (subset of Users): {trader_count:,}')\n",
        "\n",
        "        print()\n",
        "\n",
        "        # ====================================================================\n",
        "        # 2. RELATIONSHIP COUNTS\n",
        "        # ====================================================================\n",
        "        print('[2/7] Counting Relationships...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        result = session.run('''\n",
        "            MATCH ()-[r]->()\n",
        "            RETURN type(r) as rel_type, count(r) as count\n",
        "            ORDER BY count DESC\n",
        "        ''')\n",
        "\n",
        "        rel_data = list(result)\n",
        "        for record in tqdm(rel_data, desc='Relationship Types'):\n",
        "            print(f'  ‚Ä¢ {record[\"rel_type\"]}: {record[\"count\"]:,}')\n",
        "\n",
        "        total_rels = sum(r['count'] for r in rel_data)\n",
        "        print(f'\\n  Total Relationships: {total_rels:,}')\n",
        "        print()\n",
        "\n",
        "        # ====================================================================\n",
        "        # 3. DATA QUALITY CHECKS\n",
        "        # ====================================================================\n",
        "        print('[3/7] Data Quality Checks...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        checks = [\n",
        "            ('Events without Markets', 'MATCH (e:Event) WHERE NOT (e)<-[:PART_OF_EVENT]-() RETURN count(e) as count'),\n",
        "            ('Markets without Events', 'MATCH (m:Market) WHERE NOT (m)-[:PART_OF_EVENT]->() RETURN count(m) as count'),\n",
        "            ('Markets without Outcomes', 'MATCH (m:Market) WHERE NOT (m)-[:HAS_OUTCOME]->() RETURN count(m) as count'),\n",
        "            ('Trades without Users', 'MATCH (t:Trade) WHERE NOT ()-[:PLACED_TRADE]->(t) RETURN count(t) as count'),\n",
        "            ('Trades without Markets', 'MATCH (t:Trade) WHERE NOT (t)-[:ON_MARKET]->() RETURN count(t) as count'),\n",
        "            ('Users without Trades', 'MATCH (u:User {role: \"trader\"}) WHERE NOT (u)-[:PLACED_TRADE]->() RETURN count(u) as count'),\n",
        "        ]\n",
        "\n",
        "        all_checks_passed = True\n",
        "        for check_name, query in tqdm(checks, desc='Quality Checks'):\n",
        "            result = session.run(query)\n",
        "            count = result.single()['count']\n",
        "            status = '‚úÖ' if count == 0 else '‚ö†Ô∏è'\n",
        "            print(f'  {status} {check_name}: {count}')\n",
        "            if count > 0:\n",
        "                all_checks_passed = False\n",
        "\n",
        "        if all_checks_passed:\n",
        "            print('\\n  ‚úÖ All quality checks passed!')\n",
        "        else:\n",
        "            print('\\n  ‚ö†Ô∏è  Some quality issues detected (see above)')\n",
        "        print()\n",
        "\n",
        "        # ====================================================================\n",
        "        # 4. MARKET RESOLUTION STATUS\n",
        "        # ====================================================================\n",
        "        print('[4/7] Market Resolution Analysis...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        result = session.run('''\n",
        "            MATCH (m:Market)\n",
        "            RETURN\n",
        "                sum(CASE WHEN m.resolved = true THEN 1 ELSE 0 END) as resolved_count,\n",
        "                sum(CASE WHEN m.closed = true THEN 1 ELSE 0 END) as closed_count,\n",
        "                sum(CASE WHEN m.active = true THEN 1 ELSE 0 END) as active_count,\n",
        "                count(m) as total_count\n",
        "        ''')\n",
        "\n",
        "        record = result.single()\n",
        "        print(f'  ‚Ä¢ Resolved Markets: {record[\"resolved_count\"]:,} ({record[\"resolved_count\"]/record[\"total_count\"]*100:.1f}%)')\n",
        "        print(f'  ‚Ä¢ Closed Markets: {record[\"closed_count\"]:,} ({record[\"closed_count\"]/record[\"total_count\"]*100:.1f}%)')\n",
        "        print(f'  ‚Ä¢ Active Markets: {record[\"active_count\"]:,} ({record[\"active_count\"]/record[\"total_count\"]*100:.1f}%)')\n",
        "        print(f'  ‚Ä¢ Total Markets: {record[\"total_count\"]:,}')\n",
        "\n",
        "        # Show resolved markets with winners.\n",
        "        print('\\n  Sample Resolved Markets:')\n",
        "        result = session.run('''\n",
        "            MATCH (m:Market)\n",
        "            WHERE m.resolved = true AND m.winning_outcome IS NOT NULL\n",
        "            RETURN m.question as question, m.winning_outcome as winner, m.volume as volume\n",
        "            ORDER BY m.volume DESC\n",
        "            LIMIT 3\n",
        "        ''')\n",
        "\n",
        "        for record in result:\n",
        "            print(f'    ‚Ä¢ \"{record[\"question\"][:50]}...\"')\n",
        "            print(f'      Winner: {record[\"winner\"]} | Volume: ${record[\"volume\"]:,.2f}')\n",
        "        print()\n",
        "\n",
        "        # ====================================================================\n",
        "        # 5. TRADING VOLUME ANALYSIS\n",
        "        # ====================================================================\n",
        "        print('[5/7] Trading Volume Analysis...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        result = session.run('''\n",
        "            MATCH (t:Trade)\n",
        "            RETURN\n",
        "                sum(t.size_usdc) as total_volume,\n",
        "                avg(t.size_usdc) as avg_trade_size,\n",
        "                min(t.size_usdc) as min_trade,\n",
        "                max(t.size_usdc) as max_trade,\n",
        "                count(t) as trade_count\n",
        "        ''')\n",
        "\n",
        "        record = result.single()\n",
        "        print(f'  ‚Ä¢ Total Volume: ${record[\"total_volume\"]:,.2f} USDC')\n",
        "        print(f'  ‚Ä¢ Average Trade Size: ${record[\"avg_trade_size\"]:,.2f} USDC')\n",
        "        print(f'  ‚Ä¢ Smallest Trade: ${record[\"min_trade\"]:,.2f} USDC')\n",
        "        print(f'  ‚Ä¢ Largest Trade: ${record[\"max_trade\"]:,.2f} USDC')\n",
        "        print(f'  ‚Ä¢ Total Trades: {record[\"trade_count\"]:,}')\n",
        "\n",
        "        # BUY vs SELL ratio.\n",
        "        result = session.run('''\n",
        "            MATCH (t:Trade)\n",
        "            RETURN\n",
        "                t.side as side,\n",
        "                count(t) as count,\n",
        "                sum(t.size_usdc) as volume\n",
        "            ORDER BY count DESC\n",
        "        ''')\n",
        "\n",
        "        print('\\n  Trade Side Distribution:')\n",
        "        for record in result:\n",
        "            print(f'    ‚Ä¢ {record[\"side\"]}: {record[\"count\"]:,} trades (${record[\"volume\"]:,.2f})')\n",
        "        print()\n",
        "\n",
        "        # ====================================================================\n",
        "        # 6. TOP PERFORMERS\n",
        "        # ====================================================================\n",
        "        print('[6/7] Top Performers...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        # Top traders by volume.\n",
        "        print('  Top 5 Traders by Volume:')\n",
        "        result = session.run('''\n",
        "            MATCH (u:User)-[:PLACED_TRADE]->(t:Trade)\n",
        "            WITH u, sum(t.size_usdc) as total_volume, count(t) as trade_count\n",
        "            RETURN u.address as trader, total_volume, trade_count\n",
        "            ORDER BY total_volume DESC\n",
        "            LIMIT 5\n",
        "        ''')\n",
        "\n",
        "        for idx, record in enumerate(result, 1):\n",
        "            print(f'    {idx}. {record[\"trader\"][:20]}...')\n",
        "            print(f'       Volume: ${record[\"total_volume\"]:,.2f} | Trades: {record[\"trade_count\"]}')\n",
        "\n",
        "        # Top markets by volume.\n",
        "        print('\\n  Top 5 Markets by Volume:')\n",
        "        result = session.run('''\n",
        "            MATCH (m:Market)\n",
        "            RETURN m.question as question, m.volume as volume, m.slug as slug\n",
        "            ORDER BY m.volume DESC\n",
        "            LIMIT 5\n",
        "        ''')\n",
        "\n",
        "        for idx, record in enumerate(result, 1):\n",
        "            print(f'    {idx}. {record[\"question\"][:50]}...')\n",
        "            print(f'       Volume: ${record[\"volume\"]:,.2f}')\n",
        "\n",
        "        # Top events by volume.\n",
        "        print('\\n  Top 5 Events by Volume:')\n",
        "        result = session.run('''\n",
        "            MATCH (e:Event)\n",
        "            RETURN e.title as title, e.volume as volume, e.category as category\n",
        "            ORDER BY e.volume DESC\n",
        "            LIMIT 5\n",
        "        ''')\n",
        "\n",
        "        for idx, record in enumerate(result, 1):\n",
        "            print(f'    {idx}. {record[\"title\"][:40]}...')\n",
        "            print(f'       Category: {record[\"category\"]} | Volume: ${record[\"volume\"]:,.2f}')\n",
        "        print()\n",
        "\n",
        "        # ====================================================================\n",
        "        # 7. SAMPLE GRAPH PATHS\n",
        "        # ====================================================================\n",
        "        print('[7/7] Sample Graph Paths...')\n",
        "        print('-' * 70)\n",
        "\n",
        "        # User ‚Üí Trade ‚Üí Market ‚Üí Event path.\n",
        "        print('  Path: User ‚Üí Trade ‚Üí Market ‚Üí Event')\n",
        "        result = session.run('''\n",
        "            MATCH path = (u:User)-[:PLACED_TRADE]->(t:Trade)\n",
        "                         -[:ON_MARKET]->(m:Market)-[:PART_OF_EVENT]->(e:Event)\n",
        "            RETURN u.address as user, t.side as side, t.size_usdc as size,\n",
        "                   t.price as price, m.question as market, e.title as event\n",
        "            LIMIT 3\n",
        "        ''')\n",
        "\n",
        "        for record in result:\n",
        "            print(f'    ‚Ä¢ User: {record[\"user\"][:20]}...')\n",
        "            print(f'      Trade: {record[\"side\"]} ${record[\"size\"]:.2f} @ {record[\"price\"]:.3f}')\n",
        "            print(f'      Market: \"{record[\"market\"][:40]}...\"')\n",
        "            print(f'      Event: \"{record[\"event\"][:40]}...\"')\n",
        "            print()\n",
        "\n",
        "        # Group markets.\n",
        "        print('  Group Markets (SAME_GROUP):')\n",
        "        result = session.run('''\n",
        "            MATCH (m1:Market)-[r:SAME_GROUP]->(m2:Market)\n",
        "            WITH r.group_id as group_id, collect(DISTINCT m1.group_item_title)[0..3] as sample_options\n",
        "            RETURN group_id, sample_options, size(sample_options) as option_count\n",
        "            LIMIT 2\n",
        "        ''')\n",
        "\n",
        "        for record in result:\n",
        "            print(f'    ‚Ä¢ Group: {record[\"group_id\"][:25]}...')\n",
        "            print(f'      Options: {\", \".join(record[\"sample_options\"])}')\n",
        "            print()\n",
        "\n",
        "# Run verification.\n",
        "verify_database(neo4j_driver)\n",
        "\n",
        "print('=' * 70)\n",
        "print('‚úÖ Database Verification Complete!')\n",
        "print('=' * 70)\n"
      ],
      "metadata": {
        "id": "EDoHoLH-0LQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}